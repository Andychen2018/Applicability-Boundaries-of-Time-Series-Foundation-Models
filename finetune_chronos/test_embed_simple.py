#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•embedåŠŸèƒ½ï¼Œä½¿ç”¨æ›´å°çš„æ•°æ®
"""

import pandas as pd
import numpy as np
import torch

def test_simple_embed():
    """ä½¿ç”¨ç®€å•æ•°æ®æµ‹è¯•embed"""
    
    print("æµ‹è¯•ç®€å•embedåŠŸèƒ½...")
    
    try:
        from chronos import ChronosPipeline
        print("âœ… æˆåŠŸå¯¼å…¥ChronosPipeline")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # å°è¯•åŠ è½½åŸå§‹æ¨¡å‹
    try:
        pipeline = ChronosPipeline.from_pretrained(
            "/home/deep/TimeSeries/Zhendong/chronos_models/chronos-bolt-base",
            device_map="cpu",
            torch_dtype=torch.float32,
        )
        print("âœ… æˆåŠŸåŠ è½½æ¨¡å‹!")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•ä¸åŒçš„æ•°æ®
    test_cases = [
        ("å°æ•°æ®", torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])),
        ("ä¸­ç­‰æ•°æ®", torch.randn(50)),
        ("æ­£å¸¸æ•°æ®", torch.randn(100)),
        ("é•¿æ•°æ®", torch.randn(512)),
    ]
    
    for name, data in test_cases:
        print(f"\næµ‹è¯• {name} (é•¿åº¦: {len(data)})...")
        
        try:
            embeddings, tokenizer_state = pipeline.embed(data)
            print(f"  âœ… æˆåŠŸ! Embeddings shape: {embeddings.shape}")
            print(f"  Embeddings dtype: {embeddings.dtype}")
            print(f"  Embeddings range: [{embeddings.min():.4f}, {embeddings.max():.4f}]")
            
            if len(embeddings.shape) == 2:
                print(f"  åºåˆ—é•¿åº¦: {embeddings.shape[0]}, ç‰¹å¾ç»´åº¦: {embeddings.shape[1]}")
            
            return pipeline, embeddings  # è¿”å›æˆåŠŸçš„ç»“æœ
            
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            continue
    
    return None, None

def test_real_data_simple(pipeline):
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•"""
    
    if pipeline is None:
        print("æ²¡æœ‰å¯ç”¨çš„pipeline")
        return
    
    print("\næµ‹è¯•çœŸå®æ•°æ®...")
    
    # åŠ è½½çœŸå®æ•°æ®
    test_df = pd.read_csv("/home/deep/TimeSeries/Zhendong/output/test_data.csv")
    zhendong_test = test_df[test_df['item_id'].str.startswith('ZhenDong')]
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªåºåˆ—
    first_item = zhendong_test['item_id'].iloc[0]
    item_data = zhendong_test[zhendong_test['item_id'] == first_item]
    
    print(f"æµ‹è¯•åºåˆ—: {first_item}")
    print(f"æ ‡ç­¾: {item_data['label'].iloc[0]}")
    
    # æµ‹è¯•ä¸åŒé•¿åº¦
    test_lengths = [32, 64, 128, 256]
    
    for length in test_lengths:
        if length <= len(item_data):
            print(f"\næµ‹è¯•é•¿åº¦: {length}")
            
            # å‡†å¤‡æ•°æ®
            context_data = item_data.iloc[:length]['target'].values
            
            # æ ‡å‡†åŒ–æ•°æ®ï¼ˆé‡è¦ï¼ï¼‰
            context_data = (context_data - context_data.mean()) / (context_data.std() + 1e-8)
            context = torch.tensor(context_data, dtype=torch.float32)
            
            try:
                embeddings, tokenizer_state = pipeline.embed(context)
                print(f"  âœ… æˆåŠŸ! Embeddings shape: {embeddings.shape}")
                
                if len(embeddings.shape) == 2:
                    seq_len, hidden_dim = embeddings.shape
                    print(f"  åºåˆ—é•¿åº¦: {seq_len}, éšè—ç»´åº¦: {hidden_dim}")
                    
                    # å°è¯•ä¸åŒçš„æ± åŒ–æ–¹å¼
                    mean_pool = embeddings.mean(dim=0)
                    print(f"  Mean pooling shape: {mean_pool.shape}")
                    print(f"  è¿™å°±æ˜¯æˆ‘ä»¬è¦çš„ç‰¹å¾å‘é‡!")
                    
                    return embeddings, mean_pool
                
            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    return None, None

def main():
    print("å¼€å§‹ç®€å•embedæµ‹è¯•...")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    pipeline, sample_embeddings = test_simple_embed()
    
    # æµ‹è¯•çœŸå®æ•°æ®
    if pipeline:
        real_embeddings, pooled_features = test_real_data_simple(pipeline)
        
        if pooled_features is not None:
            print(f"\nğŸ‰ æˆåŠŸæå–ç‰¹å¾!")
            print(f"ç‰¹å¾ç»´åº¦: {pooled_features.shape}")
            print(f"è¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„çœŸæ­£embeddings!")
    
    print("\næµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
