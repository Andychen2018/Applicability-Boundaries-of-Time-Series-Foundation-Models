#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½å™¨æ¨¡å—
è´Ÿè´£ä»data3ç›®å½•åŠ è½½ç”µæœºæ—¶åºæ•°æ®ï¼ŒåŒ…å«æ•°æ®ç»Ÿè®¡å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import yaml
import json
from datetime import datetime

class MotorDataLoader:
    """ç”µæœºæ•°æ®åŠ è½½å™¨"""

    def __init__(self, config_path: str):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)

        self.data_path = Path(self.config['data']['path'])
        self.sensors = self.config['data']['sensors']
        self.states = self.config['data']['states']
        self.sampling_rate = self.config['data']['sampling_rate']
        self.output_path = Path(self.config['output']['tables'])
        self.image_path = Path(self.config['output']['images'])

        # è®¾ç½®matplotlibå­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['figure.figsize'] = (12, 8)

    def load_all_data(self, max_files_per_state: Optional[int] = None) -> Dict:
        """åŠ è½½æ‰€æœ‰æ•°æ®"""
        print("ğŸ“‚ å¼€å§‹åŠ è½½ç”µæœºæ•°æ®...")
        data = {}
        file_info = {}

        for sensor in self.sensors:
            data[sensor] = {}
            file_info[sensor] = {}

            for state in self.states:
                state_path = self.data_path / sensor / state
                if state_path.exists():
                    signals, files = self._load_state_data(state_path, max_files_per_state)
                    data[sensor][state] = signals
                    file_info[sensor][state] = files
                    print(f"âœ… åŠ è½½ {sensor}/{state}: {len(signals)} ä¸ªæ–‡ä»¶")
                else:
                    print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: {state_path}")
                    data[sensor][state] = []
                    file_info[sensor][state] = []

        # ä¿å­˜æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        self._save_data_statistics(data, file_info)

        return data, file_info

    def _load_state_data(self, state_path: Path, max_files: Optional[int] = None) -> Tuple[List[np.ndarray], List[str]]:
        """åŠ è½½ç‰¹å®šçŠ¶æ€çš„æ•°æ®"""
        signals = []
        file_names = []
        csv_files = list(state_path.glob("*.csv"))

        if max_files:
            csv_files = csv_files[:max_files]

        for file_path in csv_files:
            try:
                df = pd.read_csv(file_path, header=None)
                signal = df.iloc[:, 0].values if len(df.columns) == 1 else df.values.flatten()

                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if len(signal) > 100 and not np.all(np.isnan(signal)):
                    signals.append(signal)
                    file_names.append(file_path.name)

            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥ {file_path}: {e}")

        return signals, file_names

    def _save_data_statistics(self, data: Dict, file_info: Dict):
        """ä¿å­˜æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        stats = []

        for sensor in self.sensors:
            for state in self.states:
                signals = data[sensor][state]
                if signals:
                    lengths = [len(signal) for signal in signals]

                    stat_row = {
                        'sensor': sensor,
                        'state': state,
                        'file_count': len(signals),
                        'min_length': min(lengths),
                        'max_length': max(lengths),
                        'mean_length': np.mean(lengths),
                        'std_length': np.std(lengths),
                        'total_samples': sum(lengths)
                    }
                    stats.append(stat_row)

        # ä¿å­˜ä¸ºCSV
        stats_df = pd.DataFrame(stats)
        stats_path = self.output_path / 'data_statistics.csv'
        stats_df.to_csv(stats_path, index=False)
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡å·²ä¿å­˜: {stats_path}")

        # ä¿å­˜ä¸ºJSON
        json_path = self.output_path / 'data_info.json'
        data_info = {
            'timestamp': datetime.now().isoformat(),
            'sampling_rate': self.sampling_rate,
            'statistics': stats,
            'file_info': file_info
        }

        with open(json_path, 'w') as f:
            json.dump(data_info, f, indent=2, default=str)
        print(f"ğŸ“‹ æ•°æ®ä¿¡æ¯å·²ä¿å­˜: {json_path}")

    def analyze_data_distribution(self, data: Dict) -> Dict:
        """åˆ†ææ•°æ®åˆ†å¸ƒ"""
        print("ğŸ“ˆ åˆ†ææ•°æ®åˆ†å¸ƒ...")

        analysis = {}

        for sensor in self.sensors:
            analysis[sensor] = {}

            for state in self.states:
                signals = data[sensor][state]
                if not signals:
                    continue

                # è®¡ç®—ç»Ÿè®¡ç‰¹å¾
                all_values = np.concatenate(signals)
                lengths = [len(signal) for signal in signals]

                state_analysis = {
                    'signal_count': len(signals),
                    'total_samples': len(all_values),
                    'length_stats': {
                        'min': min(lengths),
                        'max': max(lengths),
                        'mean': np.mean(lengths),
                        'std': np.std(lengths)
                    },
                    'amplitude_stats': {
                        'min': float(np.min(all_values)),
                        'max': float(np.max(all_values)),
                        'mean': float(np.mean(all_values)),
                        'std': float(np.std(all_values)),
                        'skewness': float(pd.Series(all_values).skew()),
                        'kurtosis': float(pd.Series(all_values).kurtosis())
                    }
                }

                analysis[sensor][state] = state_analysis

        return analysis

    def visualize_data_overview(self, data: Dict, analysis: Dict):
        """å¯è§†åŒ–æ•°æ®æ¦‚è§ˆ"""
        print("ğŸ¨ ç”Ÿæˆæ•°æ®å¯è§†åŒ–...")

        # 1. æ•°æ®é‡ç»Ÿè®¡å›¾
        self._plot_data_counts(data)

        # 2. ä¿¡å·é•¿åº¦åˆ†å¸ƒ
        self._plot_length_distribution(data)

        # 3. å…¸å‹ä¿¡å·æ³¢å½¢å¯¹æ¯”
        self._plot_signal_comparison(data)

        # 4. å¹…å€¼åˆ†å¸ƒå¯¹æ¯”
        self._plot_amplitude_distribution(data)

        print("âœ… æ•°æ®å¯è§†åŒ–å®Œæˆ")

    def _plot_data_counts(self, data: Dict):
        """ç»˜åˆ¶æ•°æ®é‡ç»Ÿè®¡å›¾"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))

        # å‡†å¤‡æ•°æ®
        sensors = []
        states = []
        counts = []

        for sensor in self.sensors:
            for state in self.states:
                sensors.append(sensor)
                states.append(state)
                counts.append(len(data[sensor][state]))

        # åˆ›å»ºDataFrame
        df = pd.DataFrame({
            'Sensor': sensors,
            'State': states,
            'Count': counts
        })

        # æŒ‰ä¼ æ„Ÿå™¨åˆ†ç»„çš„æŸ±çŠ¶å›¾
        sensor_counts = df.groupby('Sensor')['Count'].sum()
        axes[0].bar(sensor_counts.index, sensor_counts.values, color=['skyblue', 'lightcoral'])
        axes[0].set_title('Files Count by Sensor')
        axes[0].set_ylabel('Number of Files')

        # æŒ‰çŠ¶æ€åˆ†ç»„çš„æŸ±çŠ¶å›¾
        state_counts = df.groupby('State')['Count'].sum()
        colors = ['green', 'orange', 'red']
        axes[1].bar(state_counts.index, state_counts.values, color=colors)
        axes[1].set_title('Files Count by State')
        axes[1].set_ylabel('Number of Files')

        plt.tight_layout()
        save_path = self.image_path / 'data_exploration' / 'data_counts.png'
        save_path.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡å›¾å·²ä¿å­˜: {save_path}")

    def _plot_length_distribution(self, data: Dict):
        """ç»˜åˆ¶ä¿¡å·é•¿åº¦åˆ†å¸ƒ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()

        plot_idx = 0
        colors = ['green', 'orange', 'red']

        for sensor in self.sensors:
            lengths_by_state = {}

            for i, state in enumerate(self.states):
                signals = data[sensor][state]
                if signals:
                    lengths = [len(signal) for signal in signals]
                    lengths_by_state[state] = lengths

                    # ç›´æ–¹å›¾
                    axes[plot_idx].hist(lengths, bins=20, alpha=0.7,
                                      label=state, color=colors[i])

            axes[plot_idx].set_title(f'{sensor} - Signal Length Distribution')
            axes[plot_idx].set_xlabel('Signal Length')
            axes[plot_idx].set_ylabel('Frequency')
            axes[plot_idx].legend()
            axes[plot_idx].grid(True, alpha=0.3)
            plot_idx += 1

        # æ•´ä½“é•¿åº¦åˆ†å¸ƒå¯¹æ¯”
        all_lengths = {}
        for state in self.states:
            all_lengths[state] = []
            for sensor in self.sensors:
                signals = data[sensor][state]
                if signals:
                    all_lengths[state].extend([len(signal) for signal in signals])

        for i, (state, lengths) in enumerate(all_lengths.items()):
            if lengths:
                axes[plot_idx].hist(lengths, bins=30, alpha=0.7,
                                  label=state, color=colors[i])

        axes[plot_idx].set_title('Overall Signal Length Distribution')
        axes[plot_idx].set_xlabel('Signal Length')
        axes[plot_idx].set_ylabel('Frequency')
        axes[plot_idx].legend()
        axes[plot_idx].grid(True, alpha=0.3)

        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(plot_idx + 1, len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()
        save_path = self.image_path / 'data_exploration' / 'length_distribution.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"ğŸ“ é•¿åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")

    def _plot_signal_comparison(self, data: Dict):
        """ç»˜åˆ¶å…¸å‹ä¿¡å·æ³¢å½¢å¯¹æ¯”"""
        fig, axes = plt.subplots(len(self.sensors), len(self.states),
                                figsize=(15, 10))

        if len(self.sensors) == 1:
            axes = axes.reshape(1, -1)

        colors = ['green', 'orange', 'red']

        for i, sensor in enumerate(self.sensors):
            for j, state in enumerate(self.states):
                signals = data[sensor][state]

                if signals:
                    # é€‰æ‹©ç¬¬ä¸€ä¸ªä¿¡å·ä½œä¸ºä»£è¡¨
                    signal = signals[0]

                    # åªæ˜¾ç¤ºå‰5000ä¸ªç‚¹ä»¥æé«˜å¯è§†åŒ–æ•ˆæœ
                    display_length = min(5000, len(signal))
                    time_axis = np.arange(display_length) / self.sampling_rate

                    axes[i, j].plot(time_axis, signal[:display_length],
                                  color=colors[j], linewidth=0.8)
                    axes[i, j].set_title(f'{sensor} - {state}')
                    axes[i, j].set_xlabel('Time (s)')
                    axes[i, j].set_ylabel('Amplitude')
                    axes[i, j].grid(True, alpha=0.3)

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    mean_val = np.mean(signal)
                    std_val = np.std(signal)
                    axes[i, j].text(0.02, 0.98,
                                   f'Mean: {mean_val:.3f}\nStd: {std_val:.3f}',
                                   transform=axes[i, j].transAxes,
                                   verticalalignment='top',
                                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                else:
                    axes[i, j].text(0.5, 0.5, 'No Data',
                                   transform=axes[i, j].transAxes,
                                   ha='center', va='center')
                    axes[i, j].set_title(f'{sensor} - {state}')

        plt.tight_layout()
        save_path = self.image_path / 'data_exploration' / 'signal_comparison.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"ğŸ“ˆ ä¿¡å·å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")

    def _plot_amplitude_distribution(self, data: Dict):
        """ç»˜åˆ¶å¹…å€¼åˆ†å¸ƒå¯¹æ¯”"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()

        colors = ['green', 'orange', 'red']
        plot_idx = 0

        # æŒ‰ä¼ æ„Ÿå™¨åˆ†åˆ«ç»˜åˆ¶
        for sensor in self.sensors:
            for i, state in enumerate(self.states):
                signals = data[sensor][state]
                if signals:
                    # åˆå¹¶æ‰€æœ‰ä¿¡å·çš„å¹…å€¼
                    all_amplitudes = np.concatenate(signals)

                    # ç§»é™¤å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
                    mean_amp = np.mean(all_amplitudes)
                    std_amp = np.std(all_amplitudes)
                    filtered_amp = all_amplitudes[
                        np.abs(all_amplitudes - mean_amp) <= 3 * std_amp
                    ]

                    axes[plot_idx].hist(filtered_amp, bins=50, alpha=0.7,
                                      label=state, color=colors[i], density=True)

            axes[plot_idx].set_title(f'{sensor} - Amplitude Distribution')
            axes[plot_idx].set_xlabel('Amplitude')
            axes[plot_idx].set_ylabel('Density')
            axes[plot_idx].legend()
            axes[plot_idx].grid(True, alpha=0.3)
            plot_idx += 1

        # æ•´ä½“åˆ†å¸ƒå¯¹æ¯”
        for i, state in enumerate(self.states):
            all_amplitudes = []
            for sensor in self.sensors:
                signals = data[sensor][state]
                if signals:
                    all_amplitudes.extend(np.concatenate(signals))

            if all_amplitudes:
                all_amplitudes = np.array(all_amplitudes)
                # ç§»é™¤å¼‚å¸¸å€¼
                mean_amp = np.mean(all_amplitudes)
                std_amp = np.std(all_amplitudes)
                filtered_amp = all_amplitudes[
                    np.abs(all_amplitudes - mean_amp) <= 3 * std_amp
                ]

                axes[plot_idx].hist(filtered_amp, bins=50, alpha=0.7,
                                  label=state, color=colors[i], density=True)

        axes[plot_idx].set_title('Overall Amplitude Distribution')
        axes[plot_idx].set_xlabel('Amplitude')
        axes[plot_idx].set_ylabel('Density')
        axes[plot_idx].legend()
        axes[plot_idx].grid(True, alpha=0.3)

        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(plot_idx + 1, len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()
        save_path = self.image_path / 'data_exploration' / 'amplitude_distribution.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"ğŸ“Š å¹…å€¼åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")

if __name__ == "__main__":
    # æ•°æ®åŠ è½½å’Œåˆ†æ
    config_path = Path(__file__).parent.parent.parent / "experiments/configs/config.yaml"
    loader = MotorDataLoader(str(config_path))

    # åŠ è½½æ•°æ®ï¼ˆé™åˆ¶æ¯ä¸ªçŠ¶æ€æœ€å¤š50ä¸ªæ–‡ä»¶ä»¥åŠ å¿«å¤„ç†ï¼‰
    data, file_info = loader.load_all_data(max_files_per_state=50)

    # åˆ†ææ•°æ®åˆ†å¸ƒ
    analysis = loader.analyze_data_distribution(data)

    # ç”Ÿæˆå¯è§†åŒ–
    loader.visualize_data_overview(data, analysis)

    # æ‰“å°æ€»ç»“
    total_files = sum(len(data[sensor][state])
                     for sensor in loader.sensors
                     for state in loader.states)
    print(f"\nğŸ‰ æ•°æ®æ¢ç´¢å®Œæˆï¼")
    print(f"ğŸ“Š æ€»è®¡åŠ è½½ {total_files} ä¸ªä¿¡å·æ–‡ä»¶")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {loader.output_path} å’Œ {loader.image_path}")

    # æ‰“å°ç®€è¦ç»Ÿè®¡
    print(f"\nğŸ“‹ æ•°æ®æ¦‚è§ˆ:")
    for sensor in loader.sensors:
        print(f"  {sensor}:")
        for state in loader.states:
            count = len(data[sensor][state])
            print(f"    {state}: {count} ä¸ªæ–‡ä»¶")
